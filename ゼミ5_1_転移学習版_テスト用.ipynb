{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlidA0M1amYPQLUmxJVgmg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jun-vvn/AI_lab/blob/main/%E3%82%BC%E3%83%9F5_1_%E8%BB%A2%E7%A7%BB%E5%AD%A6%E7%BF%92%E7%89%88_%E3%83%86%E3%82%B9%E3%83%88%E7%94%A8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BD9HDFBvONFy"
      },
      "outputs": [],
      "source": [
        "!pip install japanize_matplotlib | tail -n 1\n",
        "!pip install torchviz | tail -n 1\n",
        "!pip install torchinfo | tail -n 1\n",
        "w = !apt install tree\n",
        "print(w[-2])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 必要ライブラリのインポート\n",
        "\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import japanize_matplotlib"
      ],
      "metadata": {
        "id": "lEb98nBmOg8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch関連ライブラリのインポート\n",
        "\n",
        "import torch\n",
        "from torch import tensor\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchinfo import summary\n",
        "from torchviz import make_dot\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.datasets as datasets"
      ],
      "metadata": {
        "id": "ZxJD3hR5Og_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# warning表示off\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "# デフォルトフォントサイズ変更\n",
        "plt.rcParams['font.size'] = 14\n",
        "\n",
        "# デフォルトグラフサイズ変更\n",
        "plt.rcParams['figure.figsize'] = (6,6)\n",
        "\n",
        "# デフォルトで方眼表示ON\n",
        "plt.rcParams['axes.grid'] = True\n",
        "\n",
        "# numpyの表示桁数設定\n",
        "np.set_printoptions(suppress=True, precision=5)"
      ],
      "metadata": {
        "id": "_VfcalIIOhCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPUチェック\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "tZaRjio8OhEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 共通関数のダウンロード\n",
        "!git clone https://github.com/makaishi2/pythonlibs.git\n",
        "\n",
        "# 共通関数のロード\n",
        "from pythonlibs.torch_lib1 import *\n",
        "\n",
        "# 共通関数の存在チェック\n",
        "print(README)"
      ],
      "metadata": {
        "id": "Ctqr44JFOhHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "4GgwdbouOhKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = !unzip -o cifar-10.zip\n",
        "print(w[-1])"
      ],
      "metadata": {
        "id": "W3U2iTiMOhM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tree cifar-10"
      ],
      "metadata": {
        "id": "_NyKeoIaOhPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tree -L 1 cifar-10"
      ],
      "metadata": {
        "id": "RRyrGHMpOhST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "# アップロードされたファイルのパスを修正\n",
        "zip_path = '/content/cifar-10.zip'  # /mnt/data/cifar-10.zip から変更\n",
        "extract_dir = '/content/cifar-10-extracted'\n",
        "output_base_dir = '/content/cifar-10-dataset'\n",
        "\n",
        "# クラス名（CIFAR-10形式）\n",
        "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "# ZIPファイルを展開\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "# train/test ディレクトリ構築\n",
        "train_dir = os.path.join(output_base_dir, 'train')\n",
        "test_dir = os.path.join(output_base_dir, 'test')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# クラスごとにtrain/testフォルダ作成\n",
        "for class_name in classes:\n",
        "    os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n",
        "    os.makedirs(os.path.join(test_dir, class_name), exist_ok=True)\n",
        "\n",
        "# 画像をクラスごとに振り分けて移動\n",
        "for class_name in classes:\n",
        "    # クラスの元ディレクトリを探す\n",
        "    class_dir = None\n",
        "    for root, dirs, files in os.walk(extract_dir):\n",
        "        if os.path.basename(root).lower() == class_name.lower():\n",
        "            class_dir = root\n",
        "            break\n",
        "    if not class_dir:\n",
        "        print(f'⚠️ クラス {class_name} のフォルダが見つかりませんでした。スキップします。')\n",
        "        continue\n",
        "\n",
        "    # 画像ファイルの取得とシャッフル\n",
        "    image_files = [f for f in os.listdir(class_dir) if os.path.isfile(os.path.join(class_dir, f))]\n",
        "    random.shuffle(image_files)\n",
        "\n",
        "    # 8:2の割合でtrain/testに分割\n",
        "    split_idx = int(0.8 * len(image_files))\n",
        "    train_files = image_files[:split_idx]\n",
        "    test_files = image_files[split_idx:]\n",
        "\n",
        "    # コピー実行\n",
        "    for f in train_files:\n",
        "        src = os.path.join(class_dir, f)\n",
        "        dst = os.path.join(train_dir, class_name, f)\n",
        "        shutil.copy2(src, dst)\n",
        "\n",
        "    for f in test_files:\n",
        "        src = os.path.join(class_dir, f)\n",
        "        dst = os.path.join(test_dir, class_name, f)\n",
        "        shutil.copy2(src, dst)\n",
        "\n",
        "    print(f'{class_name}: Train={len(train_files)}, Test={len(test_files)}')\n",
        "\n",
        "# 完了後、ディレクトリ構造を表示\n",
        "print(\"\\n✅ 作成されたディレクトリ構造:\")\n",
        "for split in ['train', 'test']:\n",
        "    for class_name in classes:\n",
        "        dir_path = os.path.join(output_base_dir, split, class_name)\n",
        "        num_files = len(os.listdir(dir_path)) if os.path.exists(dir_path) else 0\n",
        "        print(f'{split}/{class_name}: {num_files} files')"
      ],
      "metadata": {
        "id": "uQvyuLOpOhVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tree -L 2 cifar-10-dataset"
      ],
      "metadata": {
        "id": "kmeSN6e1OhX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(0.5,0.5)\n",
        "])\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(0.5,0.5),\n",
        "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False)\n",
        "])"
      ],
      "metadata": {
        "id": "SXdJLwT-Ohah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ツリーのベースディレクトリ\n",
        "data_dir = '/content/cifar-10-dataset'  # data_dirを修正: '/content/cifar-10-split' から変更\n",
        "\n",
        "# 訓練データディレクトリと検証データディレクトリの指定\n",
        "import os\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "test_dir = os.path.join(data_dir, 'test')  # test_dirを修正: val -> test\n",
        "\n",
        "# join関数の結果確認\n",
        "print(train_dir, test_dir)\n",
        "\n",
        "# 分類先クラスのリスト作成\n",
        "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "metadata": {
        "id": "RlkVXoKUOhc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.ImageFolder(train_dir, transform=train_transform)\n",
        "train_data2 = datasets.ImageFolder(train_dir, transform=test_transform)\n",
        "test_data = datasets.ImageFolder(test_dir, transform=test_transform)"
      ],
      "metadata": {
        "id": "sQGcEwyHOhfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'訓練データ: {len(train_data)}件')\n",
        "print(f'検証データ: {len(test_data)}件')"
      ],
      "metadata": {
        "id": "n5fIMlCYOhid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 検証データ\n",
        "# 最初の10個と最後の10個の表示\n",
        "\n",
        "plt.figure(figsize=(15, 4))\n",
        "for i in range(10):\n",
        "    ax = plt.subplot(2, 10, i + 1)\n",
        "    image, label = test_data[i]\n",
        "    img = (np.transpose(image.numpy(), (1, 2, 0)) + 1)/2\n",
        "    plt.imshow(img)\n",
        "    ax.set_title(classes[label])\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    ax = plt.subplot(2, 10, i + 11)\n",
        "    image, label = test_data[-i-1]\n",
        "    img = (np.transpose(image.numpy(), (1, 2, 0)) + 1)/2\n",
        "    plt.imshow(img)\n",
        "    ax.set_title(classes[label])\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pOCjvVrxOhlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# データローダー定義\n",
        "\n",
        "batch_size = 10\n",
        "\n",
        "# 訓練用と検証用\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(train_data2, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# イメージ表示用\n",
        "train_loader2 = DataLoader(train_data2, batch_size=50, shuffle=True)\n",
        "test_loader2 = DataLoader(test_data, batch_size=50, shuffle=False)"
      ],
      "metadata": {
        "id": "r4dx4ozfOhoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch_seed()\n",
        "show_images_labels(test_loader2, classes, None, None)"
      ],
      "metadata": {
        "id": "F89gNmjHOhq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vgg19_bnをパラメータ付きで読み込む\n",
        "from torchvision import models\n",
        "net = models.vgg19_bn(pretrained = True)\n",
        "\n",
        "# すべてのパラメータで勾配計算なしに\n",
        "for param in net.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# 乱数初期化\n",
        "torch_seed()\n",
        "\n",
        "# 最終ノードの出力を2に変更する\n",
        "# このノードのみ勾配計算をすることになる\n",
        "in_features = net.classifier[6].in_features\n",
        "net.classifier[6] = nn.Linear(in_features, 10)\n",
        "\n",
        "# AdaptiveAvgPool2d関数の取り外し\n",
        "net.avgpool = nn.Identity()\n",
        "\n",
        "# GPUの利用\n",
        "net = net.to(device)\n",
        "\n",
        "# 学習率\n",
        "lr = 0.001\n",
        "\n",
        "# 損失関数定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 最適化関数定義\n",
        "# パラメータ修正の対象を最終ノードに限定\n",
        "optimizer = optim.SGD(net.classifier[6].parameters(),lr=lr,momentum=0.9)\n",
        "\n",
        "# historyファイルも同時に初期化する\n",
        "history = np.zeros((0, 5))"
      ],
      "metadata": {
        "id": "dPxlBSWJOhtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルを再度定義（同じモデルを使う必要があります）\n",
        "model = models.resnet18(pretrained=False, num_classes=10)\n",
        "\n",
        "# モデルをGPU（CUDA）に転送\n",
        "model.to(device)\n",
        "\n",
        "# 保存したモデルの重みを読み込む\n",
        "model.load_state_dict(torch.load(model_save_path))\n",
        "print(f\"Model weights loaded from {model_save_path}\")\n",
        "\n",
        "# モデルを評価モードに設定\n",
        "model.eval()\n",
        "\n",
        "# テストループ\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():  # 推論時は勾配計算を無効化\n",
        "    for inputs, labels in testloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy of the model on the 10000 test images: {accuracy}%')"
      ],
      "metadata": {
        "id": "TcVrRKBOOjq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_history(history)"
      ],
      "metadata": {
        "id": "PL4yNQwYOhwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# 分類レポート\n",
        "print(classification_report(all_labels, all_preds, target_names=classes))\n",
        "\n",
        "# 混同行列\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', xticklabels=classes, yticklabels=classes, cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IDRTto0dOhy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 乱数初期化\n",
        "torch_seed()\n",
        "\n",
        "# 検証データへの結果表示\n",
        "show_images_labels(test_loader2, classes, net, device)"
      ],
      "metadata": {
        "id": "E2P7dKY3Ojov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "git remote add origin https://github.com/jun-vvn/AI_lab.git\n",
        "git branch -M main\n",
        "git push -u origin main"
      ],
      "metadata": {
        "id": "aLZVt4PrOjt7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "892a5fa0-09b7-4802-a6f3-f0e0ece8c29c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-1-4ebb1ac5fd62>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-4ebb1ac5fd62>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    git remote add origin https://github.com/jun-vvn/AI_lab.git\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "skZsKlGuOkAD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}